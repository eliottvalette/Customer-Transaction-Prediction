{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10385,"databundleVersionId":298493,"sourceType":"competition"}],"dockerImageVersionId":30762,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport gc\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy.stats import rankdata","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-29T14:35:53.275151Z","iopub.execute_input":"2024-08-29T14:35:53.275556Z","iopub.status.idle":"2024-08-29T14:35:56.035594Z","shell.execute_reply.started":"2024-08-29T14:35:53.275521Z","shell.execute_reply":"2024-08-29T14:35:56.034707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/santander-customer-transaction-prediction/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/santander-customer-transaction-prediction/test.csv\")\n\nfeatures = [x for x in train_df.columns if x.startswith(\"var\")]","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:35:56.037354Z","iopub.execute_input":"2024-08-29T14:35:56.037983Z","iopub.status.idle":"2024-08-29T14:36:14.974224Z","shell.execute_reply.started":"2024-08-29T14:35:56.037948Z","shell.execute_reply":"2024-08-29T14:36:14.973431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# count all values\nvar_stats = {}\nhist_series_list = []\n\nfor var in features:\n    var_stats[var] = pd.concat([train_df[var], test_df[var]]).value_counts()\n    hist_series = pd.Series(test_df[var]).map(var_stats[var])\n    hist_series = hist_series > 1\n    hist_series_list.append(hist_series)\n\n# Create the DataFrame in a single operation\nhist_df = pd.concat(hist_series_list, axis=1)\nhist_df.columns = features","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:36:14.975217Z","iopub.execute_input":"2024-08-29T14:36:14.975520Z","iopub.status.idle":"2024-08-29T14:36:22.268386Z","shell.execute_reply.started":"2024-08-29T14:36:14.975489Z","shell.execute_reply":"2024-08-29T14:36:22.267417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate correlations with the target\ncorrelations = train_df[features].corrwith(train_df['target']).to_dict()","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:36:22.269495Z","iopub.execute_input":"2024-08-29T14:36:22.269785Z","iopub.status.idle":"2024-08-29T14:36:22.819386Z","shell.execute_reply.started":"2024-08-29T14:36:22.269754Z","shell.execute_reply":"2024-08-29T14:36:22.818557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def logit(p):\n    return np.log(p) - np.log(1 - p)\n\ndef var_to_feat(vr, var_stats, feat_id, correlation):\n    new_df = pd.DataFrame()\n    new_df[\"var\"] = vr.values\n    new_df[\"hist\"] = pd.Series(vr).map(var_stats)\n    new_df[\"feature_id\"] = feat_id\n    new_df[\"var_rank\"] = new_df[\"var\"].rank() / 200000.0\n    new_df[\"weighted_rank\"] = new_df[\"var_rank\"] * correlation\n    # Each row follow the format [initial value, number of apparition of this value, feature ID (Only the number), normalized rank of the value, correlation with target]\n    return new_df.values  # df into an array\n","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:36:22.821468Z","iopub.execute_input":"2024-08-29T14:36:22.821788Z","iopub.status.idle":"2024-08-29T14:36:22.828140Z","shell.execute_reply.started":"2024-08-29T14:36:22.821754Z","shell.execute_reply":"2024-08-29T14:36:22.827244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TARGET = np.array( list(train_df['target'].values) * 200 ) # number of sample * number of variables\n\nTRAIN = []\nvar_mean = {}\nvar_var  = {}\nfor var in features:\n    tmp = var_to_feat(train_df[var], var_stats[var], int(var[4:]), correlations[var]) # feature follow the format 'val_27' so int(var[4:]) is a way to get the features index\n    var_mean[var] = np.mean(tmp[:,0])                   # compute mean\n    var_var[var]  = np.var(tmp[:,0])                    # compute variance\n    tmp[:,0] = (tmp[:,0]-var_mean[var])/var_var[var]    # apply standardization\n    TRAIN.append( tmp ) # append standardized columns in the train list\nTRAIN = np.vstack( TRAIN )\n\ndel train_df\ngc.collect()\n\nprint(TRAIN.shape, len(TARGET) )","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2024-08-29T14:36:22.829538Z","iopub.execute_input":"2024-08-29T14:36:22.829958Z","iopub.status.idle":"2024-08-29T14:36:36.699391Z","shell.execute_reply.started":"2024-08-29T14:36:22.829906Z","shell.execute_reply":"2024-08-29T14:36:36.698413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = lgb.LGBMClassifier(**{\n     'learning_rate': 0.04,\n     'num_leaves': 31,\n     'max_bin': 1023,\n     'min_child_samples': 1000,\n     'reg_alpha': 0.1,\n     'reg_lambda': 0.2,\n     'feature_fraction': 1.0,\n     'bagging_freq': 1,\n     'bagging_fraction': 0.85,\n     'objective': 'binary',\n     'n_jobs': -1,\n     'n_estimators':200,\n     'verbose':-1,})\n\nMODELS = []\nskf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n\nfor fold_, (train_indexes, valid_indexes) in enumerate(skf.split(TRAIN, TARGET)):\n    print('Fold:', fold_ )\n    model = model.fit( TRAIN[train_indexes], TARGET[train_indexes],\n                      eval_set = (TRAIN[valid_indexes], TARGET[valid_indexes]),\n                      eval_metric='auc',\n                      categorical_feature = [2] )\n    MODELS.append( model )\n\ndel TRAIN, TARGET\n_=gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-08-29T14:36:36.700718Z","iopub.execute_input":"2024-08-29T14:36:36.701460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There is so 10 models\nypred = np.zeros( (200000,200) )\nfor feat,var in enumerate(features):\n    tmp = var_to_feat(test_df[var], var_stats[var], int(var[4:]), correlations[var])\n    tmp[:,0] = (tmp[:,0]-var_mean[var])/var_var[var]\n    for model_id in range(10):\n        model = MODELS[model_id]\n        ypred[:,feat] += model.predict_proba( tmp )[:,1] / 10.\nypred = np.mean( logit(ypred), axis=1 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = test_df[['ID_code']]\nsub['target'] = ypred\nsub['target'] = sub['target'].rank() / 200000.\nsub.to_csv('golden_sub.csv', index=False)\nsub.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}